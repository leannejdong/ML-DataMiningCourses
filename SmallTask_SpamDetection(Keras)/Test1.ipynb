{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=[]\n",
    "Y=[]\n",
    "[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total= 721\n",
      "correct= 703\n",
      "accuracy= 97.50346740638003\n"
     ]
    }
   ],
   "source": [
    "def derivative(x):\n",
    "    return x*(1.0-x)\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "X = []\n",
    "Y = []\n",
    "# read the training data\n",
    "with open('train_data.csv') as f:\n",
    "    for line in f:\n",
    "        curr = line.split(',')\n",
    "        new_curr = [1]\n",
    "        for item in curr[:len(curr)-1]:\n",
    "            new_curr.append(float(item))\n",
    "        X.append(new_curr)\n",
    "        Y.append([float(curr[-1])])\n",
    "X = np.array(X)\n",
    "X = preprocessing.scale(X) # feature scaling\n",
    "Y = np.array(Y)\n",
    "# the first 2500 out of 3000 emails will serve as training data\n",
    "X_train = X[0:2500]\n",
    "Y_train = Y[0:2500]\n",
    "# the rest 500 emails will serve as testing data\n",
    "X_test = X[2500:]\n",
    "y_test = Y[2500:]\n",
    "X = X_train\n",
    "y = Y_train\n",
    "# we have 3 layers: input layer, hidden layer and output layer\n",
    "# input layer has 58 nodes (1 for each feature)\n",
    "# hidden layer has 3 nodes\n",
    "# output layer has 1 node\n",
    "dim1 = len(X_train[0])\n",
    "dim2 = 5\n",
    "# randomly initialize the weight vectors\n",
    "np.random.seed(1)\n",
    "weight0 = 2 * np.random.random((dim1, dim2))-1\n",
    "weight1 = 2 * np.random.random((dim2, 1))-1\n",
    "# you can change the number of iterations\n",
    "for j in range(25000):\n",
    "    # first evaluate the output for each training email\n",
    "    layer_0 = X_train\n",
    "    layer_1 = sigmoid(np.dot(layer_0,weight0))\n",
    "    layer_2 = sigmoid(np.dot(layer_1,weight1))\n",
    "    # calculate the error\n",
    "    layer_2_error = Y_train-layer_2\n",
    "    # perform back propagation\n",
    "    layer_2_delta = layer_2_error * derivative(layer_2)\n",
    "    layer_1_error = layer_2_delta.dot(weight1.T)\n",
    "    layer_1_delta = layer_1_error * derivative(layer_1)\n",
    "    # update the weight vectors\n",
    "    weight1 += layer_1.T.dot(layer_2_delta)\n",
    "    weight0 += layer_0.T.dot(layer_1_delta)\n",
    "# evaluation on the testing data\n",
    "layer_0 = X_test\n",
    "layer_1 = sigmoid(np.dot(layer_0,weight0))\n",
    "layer_2 = sigmoid(np.dot(layer_1,weight1))\n",
    "correct = 0\n",
    "# if the output is > 0.5, then label as spam else no spam\n",
    "for i in range(len(layer_2)):\n",
    "    if(layer_2[i][0] > 0.5):\n",
    "        layer_2[i][0] = 1\n",
    "    else:\n",
    "        layer_2[i][0] = 0\n",
    "    if(layer_2[i][0] == y_test[i][0]):\n",
    "        correct += 1\n",
    "# printing the output\n",
    "print(\"total=\", len(layer_2))\n",
    "print(\"correct=\", correct)\n",
    "print(\"accuracy=\",correct * 100.0 / len(layer_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
