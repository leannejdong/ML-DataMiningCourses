y<- c(346,1798,152,86,436,968,686,257,2435,287,1850,1320)
plot(x,y,xlab="Plot Length(m^2)",ylab="Potato Yield(kg)")
# fit least square line
fit<-lm(y~x)
fit
abline(fit,col="purple",lwd=2)
# Find Pearson correlation coefficient
cor(x,y)
# Find R^2
cor(x,y)^2
# Residual plot
plot(x,fit$residuals)
abline(h=0)
sleep4<-c(3585,4470,3068,5338,2221,4791,4435,3099,3187,3901,3868,3869,4878,3632,4518)
sleep8<-c(4965,3918,1987,4993,5220,3653,3510,3338,4100,5792,4547,3319,3336,4304,4057)
boxplot(sleep4~sleep8,horizontal=T)
sleep4<-c(3585,4470,3068,5338,2221,4791,4435,3099,3187,3901,3868,3869,4878,3632,4518)
sleep8<-c(4965,3918,1987,4993,5220,3653,3510,3338,4100,5792,4547,3319,3336,4304,4057)
boxplot(sleep4 ~ sleep8,horizontal=T)
x<-c(3585,4470,3068,5338,2221,4791,4435,3099,3187,3901,3868,3869,4878,3632,4518)
y<-c(4965,3918,1987,4993,5220,3653,3510,3338,4100,5792,4547,3319,3336,4304,4057)
boxplot(x ~ y,horizontal=T)
x<-c(3585,4470,3068,5338,2221,4791,4435,3099,3187,3901,3868,3869,4878,3632,4518)
y<-c(4965,3918,1987,4993,5220,3653,3510,3338,4100,5792,4547,3319,3336,4304,4057)
boxplot(x ~ y,horizontal=T)
x<-c(3585,4470,3068,5338,2221,4791,4435,3099,3187,3901,3868,3869,4878,3632,4518)
y<-c(4965,3918,1987,4993,5220,3653,3510,3338,4100,5792,4547,3319,3336,4304,4057)
boxplot(x ~ y,horizontal=T)
x=c(3585,4470,3068,5338,2221,4791,4435,3099,3187,3901,3868,3869,4878,3632,4518)
y=c(4965,3918,1987,4993,5220,3653,3510,3338,4100,5792,4547,3319,3336,4304,4057)
boxplot(x ~ y,horizontal=T)
x=c(3585,4470,3068,5338,2221,4791,4435,3099,3187,3901,3868,3869,4878,3632,4518)
y=c(4965,3918,1987,4993,5220,3653,3510,3338,4100,5792,4547,3319,3336,4304,4057)
boxplot(x ~ y,horizontal=T)
x=c(3585,4470,3068,5338,2221,4791,4435,3099,3187,3901,3868,3869,4878,3632,4518)
y=c(4965,3918,1987,4993,5220,3653,3510,3338,4100,5792,4547,3319,3336,4304,4057)
boxplot(x)
boxplot(x ~ y,horizontal=T)
x=c(3585,4470,3068,5338,2221,4791,4435,3099,3187,3901,3868,3869,4878,3632,4518)
y=c(4965,3918,1987,4993,5220,3653,3510,3338,4100,5792,4547,3319,3336,4304,4057)
boxplot(x~y)
boxplot(x ~ y,horizontal=T)
x=c(3585,4470,3068,5338,2221,4791,4435,3099,3187,3901,3868,3869,4878,3632,4518)
y=c(4965,3918,1987,4993,5220,3653,3510,3338,4100,5792,4547,3319,3336,4304,4057)
boxplot(x ~ y)
boxplot(x ~ y,horizontal=T)
x=c(3585,4470,3068,5338,2221,4791,4435,3099,3187,3901,3868,3869,4878,3632,4518)
y=c(4965,3918,1987,4993,5220,3653,3510,3338,4100,5792,4547,3319,3336,4304,4057)
boxplot(y)
boxplot(x ~ y,horizontal=T)
x=c(3585,4470,3068,5338,2221,4791,4435,3099,3187,3901,3868,3869,4878,3632,4518)
y=c(4965,3918,1987,4993,5220,3653,3510,3338,4100,5792,4547,3319,3336,4304,4057)
boxplot(x,y,names=c("4-hr sleep","8-hr sleep"),col=c("orange","purple"),horizontal=TRUE)
x=c(3585,4470,3068,5338,2221,4791,4435,3099,3187,3901,3868,3869,4878,3632,4518)
y=c(4965,3918,1987,4993,5220,3653,3510,3338,4100,5792,4547,3319,3336,4304,4057)
boxplot(x,y,names=c("4-hr sleep","8-hr sleep"), col=c("orange","purple"),horizontal=TRUE)
t.test(Pre,Post,alternative="two-sided", paired = FALSE, var.equal = FALSE, conf.level = 0.95)
t.test(x,y,alternative="two-sided", paired = FALSE, var.equal = FALSE, conf.level = 0.95)
t.test(x,y,alternative="two.sided", paired = FALSE, var.equal = FALSE, conf.level = 0.95)
t.test(x,y,alternative="two.sided", paired = FALSE, var.equal = FALSE, conf.level = 0.95)
t.test(x,y,alternative="two.sided", paired = FALSE,var.equal = TRUE, conf.level = 0.95)
groupA=c(4.4,3,4.1,4.4,4.5,4,4.3,4.1,3,3.7,3.1,3.8,4.5,3.7,5.1,4.2,2.8,3.6,4.1,4)
groupB=c(3.9,3.4,3.6,3.3,4,4.2,3.8,4.1,2.6,3.6,3.7,3.8,4.3,4.9,3.8,2.8,3.7,4,3.5,2.7)
t.test(groupA,groupB,alternative="two.sided", paired = FALSE,var.equal = TRUE, conf.level = 0.95)
groupA=c(4.4,3,4.1,4.4,4.5,4,4.3,4.1,3,3.7,3.1,3.8,4.5,3.7,5.1,4.2,2.8,3.6,4.1,4)
groupB=c(3.9,3.4,3.6,3.3,4,4.2,3.8,4.1,2.6,3.6,3.7,3.8,4.3,4.9,3.8,2.8,3.7,4,3.5,2.7)
summary(groupA)
summary(groupB)
t.test(groupA,groupB,alternative="two.sided", paired = FALSE,var.equal = TRUE, conf.level = 0.95)
groupA=c(4.4,3,4.1,4.4,4.5,4,4.3,4.1,3,3.7,3.1,3.8,4.5,3.7,5.1,4.2,2.8,3.6,4.1,4)
groupB=c(3.9,3.4,3.6,3.3,4,4.2,3.8,4.1,2.6,3.6,3.7,3.8,4.3,4.9,3.8,2.8,3.7,4,3.5,2.7)
var(groupA)
var(groupB)
t.test(groupA,groupB,alternative="two.sided", paired = FALSE,var.equal = TRUE, conf.level = 0.95)
t.test(groupA,groupB,alternative="two.sided", paired = FALSE,var.equal = TRUE, conf.level = 0.95)
knitr::opts_chunk$set(echo = TRUE)
twodays<-c(270,236,210,142,280,272,160,220,226,242,186,266,206,318,294)
fourdays<-c(218,234,214,116,200,276,146,182,238,288,190,236,244,258,240)
t.test(twodays,fourdays,alternative="less", paired=TRUE,conf.level = 0.95)
twodays<-c(270,236,210,142,280,272,160,220,226,242,186,266,206,318,294)
fourdays<-c(218,234,214,116,200,276,146,182,238,288,190,236,244,258,240)
t.test(twodays,fourdays,alternative="two.sided", paired=TRUE,conf.level = 0.95)
strategy1<-c(1857,1700,1829,2644,1566,663,1712,1679)
strategy2<-c(1544,2640,1645,2275,2137,2327,2152,2130)
var(strategy1)
var(strategy2)
t.test(strategy1,strategy2,alternative="two.sided", paired = FALSE,  conf.level = 0.95)
t.test(strategy1,strategy2,alternative="less than", paired = FALSE,  conf.level = 0.95)
t.test(strategy1,strategy2,alternative="less", paired = FALSE,  conf.level = 0.95)
t.test(strategy1,strategy2,alternative="greater", paired = FALSE,  conf.level = 0.95)
t.test(strategy1,strategy2,alternative="greater", paired = FALSE,var.equal = FALSE  conf.level = 0.95)
t.test(strategy1,strategy2,alternative="greater", paired = FALSE,var.equal = FALSE,  conf.level = 0.95)
t.test(strategy1,strategy2,alternative="less", paired = FALSE,var.equal = FALSE,  conf.level = 0.95)
t.test(strategy1,strategy2,alternative="less", paired = FALSE, var.equal=TRUE, conf.level = 0.95)
?t.test
knitr::opts_chunk$set(echo = TRUE)
t.test(strategy1,strategy2,alternative="less", paired = FALSE, var.equal=TRUE, conf.level = 0.95)
strategy1<-c(1857,1700,1829,2644,1566,663,1712,1679)
strategy2<-c(1544,2640,1645,2275,2137,2327,2152,2130)
var(strategy1)
var(strategy2)
t.test(strategy1,strategy2,alternative="less", paired = FALSE, var.equal=TRUE, conf.level = 0.95)
yield<-(64.5,66.5 ,67.5,67.5, 66.5, 65.0, 73.0, 63.5,68.5,70.0,71.0,68.5,68.0,64.5,69.5, 76.0)
yield<-(64.5,66.5,67.5,67.5, 66.5, 65.0, 73.0, 63.5,68.5,70.0,71.0,68.5,68.0,64.5,69.5, 76.0)
yield<-(64.5,66.5,67.5,67.5, 66.5, 65.0, 73.0, 63.5,68.5,70.0,71.0,68.5,68.0,64.5,69.5, 76.0)
yield<-(64.5,66.5,67.5,67.5, 66.5, 65.0, 73.0, 63.5,68.5,70.0,71.0,68.5,68.0,64.5,69.5, 76.0)
yield=(64.5,66.5,67.5,67.5, 66.5, 65.0, 73.0, 63.5,68.5,70.0,71.0,68.5,68.0,64.5,69.5, 76.0)
yield<-c(64.5,66.5,67.5,67.5,66.5,65.0,73.0, 63.5,68.5,70.0,71.0,68.5,68.0,64.5,69.5,76.0)
t.test(yield,alternative="two.sided",mu=70,conf.level=)
yield<-c(64.5,66.5,67.5,67.5,66.5,65.0,73.0, 63.5,68.5,70.0,71.0,68.5,68.0,64.5,69.5,76.0)
t.test(yield,alternative="two.sided",mu=70,conf.level=0.95)
yield<-c(64.5,66.5,67.5,67.5,66.5,65.0,73.0, 63.5,68.5,70.0,71.0,68.5,68.0,64.5,69.5,76.0)
mean(yield)
sd(yield)
t.test(yield,alternative="two.sided",mu=70,conf.level=0.95)
(68.125-70)/(3.3/sqrt(20))
(68.125-70)/(3.3/sqrt(16))
A<-c(27,35,19,34,39,15,32,26,17,18)
B<-c(23,28,16,38,31,17,30,22,16,15)
t.test(A,B,alternative="greater", paired=TRUE,conf.level = 0.95)
# Enter the data into vectors
slow=c(3,5,11)
medium=c(7,10,8)
fast=(12,7,5)
# Enter the data into vectors
slow=c(3,5,11)
medium=c(7,10,8)
fast=c(12,7,5)
# Combining the row vectors in matrices, then converting tinto a data frame
survey=as.data.frame(rbind(slow,medium,fast))
# Assigning column names to this data frame
names(survey)=c('low','medium','heavy')
chisq.test(survey)
sampleA=c(2,5,6,9,10)
sampleB=c(3,4,7,9,11)
wilcox.test(sampleA,sampleB,alternative="two.sided")
sampleA=c(139,136,142,133,140)
sampleB=c(148,143,138,145,142)
wilcox.test(sampleA,sampleB,alternative="two.sided")
sampleA=c(139,136,142,133,140)
sampleB=c(148,143,138,145,142)
wilcox.test(sampleA,sampleB,correct=FALSE)
sum.rank.sampleA=sum(rank(c(sampleA,sampleB))[1:5]) # sum of ranks assigned to group A
W=sum.rank.sampleA-(length(sampleA)*(length(sampleA)+1))/2
sum.rank.sampleA=sum(rank(c(sampleA,sampleB))[1:5]) # sum of ranks assigned to group A
W=sum.rank.sampleA-(length(sampleA)*(length(sampleA)+1))/2
sum.rank.sampleA=sum(rank(c(sampleA,sampleB))[1:5]) # sum of ranks assigned to group A
W=sum.rank.sampleA-(length(sampleA)*(length(sampleA)+1))/2
sum.rank.sampleA=sum(rank(c(sampleA,sampleB))[1:5]) # sum of ranks assigned to group A
W=sum.rank.sampleA-(length(sampleA)*(length(sampleA)+1))/2
W
sum.rank.sampleA=sum(rank(c(sampleA,sampleB))[1:5]) # sum of ranks assigned to group A
W=sum.rank.sampleA-(length(sampleA)*(length(sampleA)+1))/2
sum.rank.sampleA
W
sampleA=c(139,136,142,133,140)
sampleB=c(148,143,138,145,142)
wilcox.test(sampleA,sampleB,correct=FALSE)
sampleA=c(139,136,142,133,140)
sampleB=c(148,143,138,145,142)
wilcox.test(sampleA,sampleB)
sum.rank.sampleA=sum(rank(c(sampleA,sampleB))[1:5]) # sum of ranks assigned to group A
W=sum.rank.sampleA-(length(sampleA)*(length(sampleA)+1))/2
sum.rank.sampleA
W
sampleA=c(139,136,142,133,140)
sampleB=c(148,143,138,145,142)
wilcox.test(sampleA,sampleB,correct=TRUE)
sum.rank.sampleA=sum(rank(c(sampleA,sampleB))[1:5]) # sum of ranks assigned to group A
W=sum.rank.sampleA-(length(sampleA)*(length(sampleA)+1))/2
sum.rank.sampleA
W
Pre<-c(510,610,640,675,600,550,610,625,450,720,575,675)
Post<-c(850,790,850,775,700,775,700,850,690,775,540,680)
t.test(Pre,Post,alternative="less", paired=TRUE,conf.level = 0.9)
?t.test
Pre<-c(510,610,640,675,600,550,610,625,450,720,575,675)
Post<-c(850,790,850,775,700,775,700,850,690,775,540,680)
t.test(Pre,Post,alternative="two.sided", paired=TRUE,conf.level = 0.9)
qt(0.05,11)
qf(0.05,3,36)
qf(0.95,3,36)
qf(0.975,3,36)
qf(0.025,3,36)
qf(0.95,3,36)
?qf
# To make side-by-side boxplots of the oxygen concentration by the variable method, we first read data into appropriate format
concentration=c(10.96,10.77,10.9,10.69,10.87,10.6,10.88
10.75,10.8,10.81,10.7,10.82,11.13,10.99,10.98,11.02,11.02,11.08)
# To make side-by-side boxplots of the oxygen concentration by the variable method, we first read data into appropriate format
concentration=c(10.96,10.77,10.9,10.69,10.87,10.6,10.88,
10.75,10.8,10.81,10.7,10.82,11.13,10.99,10.98,11.02,11.02,11.08)
# The command rep("A",6) constructs a list of 6 Method A in a row. The variable Method is therefore a list of length 18 consisting of 6 Method followed by 6 method B followed by 6 method C.
mathod=c(rep("A",6),rep("B",6),rep("C",6))
# Print the table of controlled test scores to see the data is in order
controlled=data.frame(concentration,method)
# To make side-by-side boxplots of the oxygen concentration by the variable method, we first read data into appropriate format
concentration=c(10.96,10.77,10.9,10.69,10.87,10.6,10.88,
10.75,10.8,10.81,10.7,10.82,11.13,10.99,10.98,11.02,11.02,11.08)
# The command rep("A",6) constructs a list of 6 Method A in a row. The variable Method is therefore a list of length 18 consisting of 6 Method followed by 6 method B followed by 6 method C.
method=c(rep("A",6),rep("B",6),rep("C",6))
# Print the table of controlled test scores to see the data is in order
controlled=data.frame(concentration,method)
# Make the boxplot
plot(concentration~method,data=controlled)
# To make side-by-side boxplots of the oxygen concentration by the variable method, we first read data into appropriate format
concentration=c(10.96,10.77,10.9,10.69,10.87,10.6,10.88,
10.75,10.8,10.81,10.7,10.82,11.13,10.99,10.98,11.02,11.02,11.08)
# The command rep("A",6) constructs a list of 6 Method A in a row. The variable Method is therefore a list of length 18 consisting of 6 Method followed by 6 method B followed by 6 method C.
method=c(rep("A",6),rep("B",6),rep("C",6))
# Print the table of controlled test scores to see the data is in order
controlled=data.frame(concentration,method)
# Make the boxplot
plot(concentration~method,data=controlled)
results=aov(concentration~method,data=controlled)
# Inspect the results
summary(results)
results=aov(concentration~method,data=controlled)
# Inspect the results
summary(results)
summary(controlled)
results=aov(concentration~method,data=controlled)
# Inspect the results
summary(results)
# Enter the data into vectors
excellent=c(62,36)
satisfactory=c(84,42)
unsatisfactory=c(24,22)
# Combining the row vectors in matrices, then converting into a data frame
survey=as.data.frame(rbind(excellent,satisfactory,unsatisfactory))
# Assigning column names to this data frame
names(survey)=c('first call','later call')
chisq.test(survey)
# Enter the data into vectors
same=c(34,27,23,19)
different=c(166,123,127,81)
# Combining the row vectors in matrices, then converting into a data frame
survey=as.data.frame(rbind(same,different))
# Assigning column names to this data frame
names(survey)=c('Doctors','Bankers','Teachers','Lawyers')
chisq.test(survey)
# Enter the data into vectors
reality=c(50,31,18)
drama=c(6,22,44)
sport=c(35,37,18)
comedy=c(9,10,20)
# Combining the row vectors in matrices, then converting into a data frame
survey=as.data.frame(rbind(reality,drama,sport,comedy))
# Assigning column names to this data frame
names(survey)=c('under 15','15-24','25 and over')
chisq.test(survey)
# Enter the data into vectors
reality=c(50,31,18)
drama=c(6,22,44)
sport=c(35,37,18)
comedy=c(9,10,20)
# Combining the row vectors in matrices, then converting into a data frame
survey=as.data.frame(rbind(reality,drama,sport,comedy))
# Assigning column names to this data frame
names(survey)=c('under 15','15-24','25 and over')
chisq.test(survey)
# Enter the data into vectors
excellent=c(62,36)
satisfactory=c(84,42)
unsatisfactory=c(24,22)
# Combining the row vectors in matrices, then converting into a data frame
survey=as.data.frame(rbind(excellent,satisfactory,unsatisfactory))
# Assigning column names to this data frame
names(survey)=c('first call','later call')
chisq.test(survey)
# Enter the data into vectors
reality=c(50,31,18)
drama=c(6,22,44)
sport=c(35,37,18)
comedy=c(9,10,20)
# Combining the row vectors in matrices, then converting into a data frame
survey=as.data.frame(rbind(reality,drama,sport,comedy))
# Assigning column names to this data frame
names(survey)=c('under 15','15-24','25 and over')
chisq.test(survey)
qf(0.95,3,36)
A=c(120,136,107,109,129,117,115,110,124)
B=c(131,144,146,111,103,122,121,139,130,	133,132,135,128)
boxplot(A,B,names=c("group A","group B"),col=c("orange","purple"),horizontal=TRUE)
t.test(A,B,alternative="two.sided",paired=FALSE,var.equal=FALSE,conf.level=0.95)
t.test(A,B,alternative="two.sided",paired=FALSE,conf.level=0.95)
Milk = read.csv("http://www.maths.usyd.edu.au/u/UG/JM/DATA1001/r/2018S2/data/Milk.csv")
dim(Milk)
names(Milk)
class(Milk)
head(Milk)
mean(Milk$Yields)
hist(Milk$Yields)
boxplot(Milk$Yields)
tobs = (mean(Milk$Yields) - 11)/(sd(Milk$Yields)/sqrt(100))
tobs
2 * (1 - pnorm(tobs))
# Compare t-test
2 * (1 - pt(tobs, 99))
# Note: we use the normal distribution to approximate the t distribution
# with large degrees of freedom (sample size).
t.test(Milk$Yields, mu = 11)
Stinging = read.csv("http://www.maths.usyd.edu.au/u/UG/JM/DATA1001/r/2018S2/data/Stinging.csv")
hist(Stinging)  # Check Normality assumption, though this is only a small sample.
Stinging = read.csv("http://www.maths.usyd.edu.au/u/UG/JM/DATA1001/r/2018S2/data/Stinging.csv")
Stinging = read.csv("http://www.maths.usyd.edu.au/u/UG/JM/DATA1001/r/2018S2/data/Stinging.csv")
hist(Stinging)  # Check Normality assumption, though this is only a small sample.
Stinging = read.csv("http://www.maths.usyd.edu.au/u/UG/JM/DATA1001/r/2018S2/data/Stinging.csv")
Stinging  # Check Normality assumption, though this is only a small sample.
boxplot(Stinging)
t.test(Stinging, mu = 1.5)
data= read.csv("http://www.maths.usyd.edu.au/u/UG/JM/DATA1001/r/2018S2/data/Stinging.csv")
hist(data) # Check Normality assumption, though this is only a small sample.
data= read.csv("http://www.maths.usyd.edu.au/u/UG/JM/DATA1001/r/2018S2/data/Stinging.csv")
stinging=c(data)
hist(stinging) # Check Normality assumption, though this is only a small sample.
data= read.csv("http://www.maths.usyd.edu.au/u/UG/JM/DATA1001/r/2018S2/data/Stinging.csv")
data
Stinging= read.csv("http://www.maths.usyd.edu.au/u/UG/JM/DATA1001/r/2018S2/data/Stinging.csv")
hist(Stinging$Growth)
boxplot(Growth)
Stinging= read.csv("http://www.maths.usyd.edu.au/u/UG/JM/DATA1001/r/2018S2/data/Stinging.csv")
hist(Stinging$Growth)
boxplot(Stinging$Growth)
t.test(Stinging$Growth, mu = 1.5)
# Note: This code is extension.
n = length(Stinging)
tobs = 2.3534
curve(dt(x, 8), xlim = c(-4, 4), ylab = "", axes = FALSE)
abline(h = 0)
sequence = seq(tobs, 4, 0.1)
polygon(x = c(sequence, 4, tobs), y = c(dt(c(sequence), 8), 0, 0), col = "purple")
polygon(x = c(-1 * rev(sequence), -1 * tobs, -4), y = c(dt(-1 * rev(sequence),
8), 0, 0), col = "purple")
axis(1, at = round(c(-4, -tobs, -1, 0, 1, tobs, 4), 3), pos = 0)
Stinging= read.csv("http://www.maths.usyd.edu.au/u/UG/JM/DATA1001/r/2018S2/data/Stinging.csv")
hist(Stinging$Growth)
boxplot(Stinging$Growth)
t.test(Stinging$Growth, mu = 1.5)
1+18+5.5+11+15+3+17+6+13+8.5
12+6+19+10+8.5+4+16+20+2+14
98+111.5
20*21/2
1+18+6+11+15+3+17+6+13+8.5
69*87/180
62*87/180
49*87/180
69*93/180
62*93/180
49*93/180
(21-33.35)^2/33.35+(36-29.97)^2/29.97+(30-23.68)^2/23.68+(48-35.65)^2/35.65+(26-32.03)^2/32.03+(19-25.32)^2/25.32
library(quantmod)
install.packages("quantmod")
library(quantmod)
library(quantmod)
library(PerformanceAnalytics)
install.packages("PerformanceAnalytics")
library(quantmod)
library(PerformanceAnalytics)
maxDate<-"2000-01-01"
MSFT.prices<-Ad(getSymbols("MSFT",auto.assign = F,from=maxDate))
MSFT.rets<- dailyReturn(MSFT.prices)
VaR(MSFT.rets,p=0.95,method="historical")
VaR(MSFT.rets,p=0.99,method="historical")
CVaR(MSFT.rets,p=0.99,method="historical")
tickers<- c("MSFT","AAPL","AMZN")
weights<- c(0.5,0.1,0.4)
getSymbols(tickers,from=maxDate)
Port.prices<- na.omit(merge(Ad(MSFT),Ad(AAPL),Ad(AMZN)))
Port.returns<-ROC(Port.prices, type="discrete")[-1,]
library(quantmod)
library(PerformanceAnalytics)
maxDate<-"2000-01-01"
MSFT.prices<-Ad(getSymbols("MSFT",auto.assign = F,from=maxDate))
MSFT.rets<- dailyReturn(MSFT.prices)
VaR(MSFT.rets,p=0.95,method="historical")
VaR(MSFT.rets,p=0.99,method="historical")
CVaR(MSFT.rets,p=0.99,method="historical")
tickers<- c("MSFT","AAPL","AMZN")
weights<- c(0.5,0.1,0.4)
getSymbols(tickers,from=maxDate)
Port.prices<- na.omit(merge(Ad(MSFT),Ad(AAPL),Ad(AMZN)))
Port.returns<-ROC(Port.prices, type="discrete")[-1,]
colnames(Port.returns)<- tickers
VaR(Port.returns,p=0.99,weights=weights,portfolio_method = "component",method="modified")
$MVaR
VaR
VaR$MVaR
VaR
VaR
VaR$MVaR
VaR$contribution
VaR$pct_contrib_MVaR
$MVaR
library(stats)
install.packages(sfsmisc)
install.packages("sfsmisc")
install.packages("qrmtools")
cat basicrisk.out
R CMD BATCH basicrisk.r
library(readr)
nba<- read_csv("/Users/leannedong/Desktop/PyProject/DATA/nba_2013.csv")
dim(nba)
head(nba,1)
# Importing a CSV
library(readr)
nba<- read_csv("/Users/leannedong/Desktop/PyProject/DATA/nba_2013.csv")
# Find the number of rows and columns
dim(nba)
# Get the first row
head(nba,1)
# Find average of each statistic
library(purrr)
library(dplyr)
nba %>%
select_if(is.numeric) %>%
map_dbl(mean, na.rm = TRUE)
help(map_dbl)
# make pairwise scatterplots
library(GGally)
install.packages("GGally")
# make pairwise scatterplots
library(GGally)
nba %>%
select(ast, fg, trb) %>%
ggpairs()
# Make clusters of the players
library(cluster)
set.seed(1)
isGoodCol <- function(col){
sum(is.na(col))== 0 && is.numeric(col)
}
goodCols <- sapply(nba,isGoodCol)
clusters <- kmeans(nba[,goodCols], centers=5)
labels <- clusters$cluster
library(multicon)
# Assume support vote = 0.57/(0.57+0.32) = 0.64
box=c(rep(1,1817*0.64),rep(0,1817*0.36))
n = 1817
mean(box)
popsd(box)
ev = mean(box)
se = popsd(box)/sqrt(n)
c(ev,se)
{nnet} to Neural Networks
library(ElemStatLearn)
install.packages("ElemStatLearn")
library(ElemStatLearn)
library(ElemStatLearn)
# Fit a neural network to your training data using 2 hidden units and 0 decay.
# decay parameter for weight decay. Default 0. It is the penalty on large coefficient
nn1 <- nnet(formula = spam ~ ., data=spam.train, size=2, decay=0.1, maxit=1000)
library(ElemStatLearn)
nn1 <- nnet(formula = spam ~ ., data=spam.train, size=2, decay=0.1, maxit=1000)
help(nnet)
help(nnet())
install.packages("nnet")
data(spam)
# alternatively read the data
# spam = read.table("spam.data", header=T)
dim(spam)
summary(spam)
set.seed(42)
my.sample <- sample(nrow(spam), 3221)
spam.train <- spam[my.sample, ]
spam.test <- spam[-my.sample, ]
library(nnet)
nn1 <- nnet(formula = spam ~ ., data=spam.train, size=2, decay=0.1, maxit=1000)
summary(nn1)
nnfit = nnet(y ~ ., spam, size = 10, subset = tr);
y
nnfit = nnet(y~ ., spam, size = 10, subset = tr);
nnfit = nnet(y~., spam, size = 10, subset = tr);
library(nnet)
library(mlbench)
set.seed(0)
d=mlbench.2dnormals(500)
plot(d)
d=data.frame(x1=d$x[,1],x2=d$x[,2],y=d$classes)
# nnet function from nnet package
fit1<-nnet(y~.,data=d,size=10)
fit1
nn1 <- nnet(formula = spam ~ ., data=spam.train, size=2, decay=0.1, maxit=1000)
nnfit = nnet(spam ~ ., spam, size = 10, subset = tr);
nnfit = nnet(spam ~ ., spam, size = 10, subset = tr);
# Refit the neural network with 10 hidden units and 0 decay.
nnfit = nnet(spam ~ ., spam, size = 10, subset = tr);
tr = 1:2500
nn1.test.tab<-table(spam.test$spam, nn1.pr.test, dnn=c('Actual', 'Predicted'))
nn1.pr.test <- predict(nn1, spam.test, type='class')
nn1.test.tab<-table(spam.test$spam, nn1.pr.test, dnn=c('Actual', 'Predicted'))
nn1.test.tab
nn1.test.perf <- 100 * (nn1.test.tab[2] + nn1.test.tab[3]) / sum(nn1.test.tab)
nn1.test.perf
# Fit a neural network to your training data using 2 hidden units and 0 decay.
# decay parameter for weight decay. Default 0. It is the penalty on large coefficient
nn1 <- nnet(formula = spam ~ ., data=spam.train, size=2, decay=0.1, maxit=1000)
data(spam)
nn1.test.perf
getwd()
spam = read.table("/Users/leannedong/Desktop/ML-DataMiningCourses/spam.data", header=T)
spam = read.table("Users/leannedong/Desktop/ML-DataMiningCourses/spam.data", header=T)
setwd("/Users/leannedong/Desktop/ML-DataMiningCourses")
spam = read.table("spam.data", header=T)
library(ElemStatLearn)
spam = read.table("spam.data", header=T)
spam = read.table("spam.dat", header=T)
library(readr)
spam <- read_csv("Lab 13 on NNetworks to be added/spam.data")
View(spam)
spam = read.table("/Users/leannedong/Desktop/ML-DataMiningCourses/Lab 13 on NNetworks to be added/spam.dat", header=T)
dim(spam)
